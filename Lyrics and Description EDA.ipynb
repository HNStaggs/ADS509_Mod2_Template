{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f79baf9",
   "metadata": {},
   "source": [
    "# ADS 509 Assignment 2.1: Tokenization, Normalization, Descriptive Statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3173ae",
   "metadata": {},
   "source": [
    "## Halee Staggs\n",
    "### Disclaimer: This assignment was aided by ChatGPT4o. All code was verified for accuracy and the code blocks are commented where this tool was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d096b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "#!pip install emoji\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import nltk\n",
    "\n",
    "# Download the stopwords if not already downloaded\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "# Load stopwords\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b555ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional import statements you need here\n",
    "from nltk.tokenize import word_tokenize\n",
    "#nltk.download('punkt')\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "923b5a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter folder path: C:\\Users\\Halee\\Downloads\\M1AssignmentData\\M1Results\\twitter\n",
      "Lyrics folder path: C:\\Users\\Halee\\Downloads\\M1AssignmentData\\M1Results\\lyrics\n"
     ]
    }
   ],
   "source": [
    "# Location of data on machine\n",
    "data_location = r\"C:\\Users\\Halee\\Downloads\\M1AssignmentData\"\n",
    "\n",
    "# Define subfolders\n",
    "twitter_folder = os.path.join(data_location, \"M1Results\", \"twitter\")\n",
    "lyrics_folder = os.path.join(data_location, \"M1Results\", \"lyrics\")\n",
    "\n",
    "print(\"Twitter folder path:\", twitter_folder)\n",
    "print(\"Lyrics folder path:\", lyrics_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06522af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to output desc stats\n",
    "# CODE ASSISTED BY CHATGPT4O\n",
    "def descriptive_stats(tokens, num_tokens=5, verbose=True):\n",
    "\n",
    "    # Given a list of tokens...\n",
    "    total_tokens = len(tokens)  # Number of tokens\n",
    "    unique_tokens = len(set(tokens))  # Number of unique tokens\n",
    "    num_characters = sum(len(token) for token in tokens)  # Numbers of characters\n",
    "    lexical_diversity = unique_tokens / total_tokens if total_tokens > 0 else 0  # Lexical diversity\n",
    "    \n",
    "    # Calculate the most common tokens\n",
    "    token_counts = Counter(tokens)\n",
    "    most_common_tokens = token_counts.most_common(num_tokens)\n",
    "    \n",
    "    # Set up statement syntax\n",
    "    if verbose:\n",
    "        print(f\"There are {total_tokens} tokens in the data.\")\n",
    "        print(f\"There are {unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "        print(f\"The {num_tokens} most common tokens are:\")\n",
    "        for token, count in most_common_tokens:\n",
    "            print(f\"'{token}': {count} times\")\n",
    "    \n",
    "    # Return list of values\n",
    "    return [total_tokens, unique_tokens, lexical_diversity, num_characters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59dcf058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 tokens in the data.\n",
      "There are 9 unique tokens in the data.\n",
      "There are 55 characters in the data.\n",
      "The lexical diversity is 0.692 in the data.\n",
      "The 5 most common tokens are:\n",
      "'text': 3 times\n",
      "'here': 2 times\n",
      "'example': 2 times\n",
      "'is': 1 times\n",
      "'some': 1 times\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"here is some example text with other example text here in this text\"\"\".split()\n",
    "assert(descriptive_stats(text, verbose=True)[0] == 13)\n",
    "assert(descriptive_stats(text, verbose=False)[1] == 9)\n",
    "assert(abs(descriptive_stats(text, verbose=False)[2] - 0.69) < 0.02)\n",
    "assert(descriptive_stats(text, verbose=False)[3] == 55)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7e1a2",
   "metadata": {},
   "source": [
    "Q: Why is it beneficial to use assertion statements in your code? \n",
    "\n",
    "A: It helps to flag errors in the code and enhance code quality. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bf93e",
   "metadata": {},
   "source": [
    "## Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37d70801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE ASSISTED BY CHATGPT4O\n",
    "# Create function to combine lyrics data into one dataframe\n",
    "def combine_lyrics_to_dataframe(directory):\n",
    "    data = []  # Create empty list to append data to\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):  # Specify to find text files with lyric data\n",
    "                try:\n",
    "                    # Get the artist name from the parent folder\n",
    "                    artist = os.path.basename(root)\n",
    "\n",
    "                    # Read the content of the file\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        lines = f.readlines()\n",
    "\n",
    "                    # Get the song name from the first line of the file\n",
    "                    songname = lines[0].strip()\n",
    "\n",
    "                    # Combine the rest of the lines into lyrics\n",
    "                    lyrics = ''.join(lines[1:]).strip()\n",
    "\n",
    "                    # Append the data to the list\n",
    "                    data.append([artist, songname, lyrics])\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file}: {e}\")  # Add bug readout\n",
    "\n",
    "    # Create the DataFrame\n",
    "    if data:\n",
    "        df = pd.DataFrame(data, columns=['artist', 'songname', 'lyrics'])\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['artist', 'songname', 'lyrics'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2539cf6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>songname</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"88 Degrees\"</td>\n",
       "      <td>Stuck in L.A., ain't got no friends \\nAnd so H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"A Different Kind Of Love Song\"</td>\n",
       "      <td>What if the world was crazy and I was sane\\nWo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"After All\"</td>\n",
       "      <td>Well, here we are again\\nI guess it must be fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Again\"</td>\n",
       "      <td>Again evening finds me at your door \\nHere to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Alfie\"</td>\n",
       "      <td>What's it all about, Alfie?\\nIs it just for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>robyn</td>\n",
       "      <td>\"We Dance To The Beat\"</td>\n",
       "      <td>We dance to the beat\\nWe dance to the beat\\nWe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>robyn</td>\n",
       "      <td>\"Where Did Our Love Go\"</td>\n",
       "      <td>Thoughts about you and me \\nThinkin' about wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>robyn</td>\n",
       "      <td>\"Who's That Girl\"</td>\n",
       "      <td>Good girls are pretty like all the time\\nI'm j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>robyn</td>\n",
       "      <td>\"With Every Heartbeat\"</td>\n",
       "      <td>Maybe we could make it all right\\nWe could mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>robyn</td>\n",
       "      <td>\"You've Got That Something\"</td>\n",
       "      <td>Look at me here I am\\nI'm givin all of my lovi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist                         songname  \\\n",
       "0     cher                     \"88 Degrees\"   \n",
       "1     cher  \"A Different Kind Of Love Song\"   \n",
       "2     cher                      \"After All\"   \n",
       "3     cher                          \"Again\"   \n",
       "4     cher                          \"Alfie\"   \n",
       "..     ...                              ...   \n",
       "415  robyn           \"We Dance To The Beat\"   \n",
       "416  robyn          \"Where Did Our Love Go\"   \n",
       "417  robyn                \"Who's That Girl\"   \n",
       "418  robyn           \"With Every Heartbeat\"   \n",
       "419  robyn      \"You've Got That Something\"   \n",
       "\n",
       "                                                lyrics  \n",
       "0    Stuck in L.A., ain't got no friends \\nAnd so H...  \n",
       "1    What if the world was crazy and I was sane\\nWo...  \n",
       "2    Well, here we are again\\nI guess it must be fa...  \n",
       "3    Again evening finds me at your door \\nHere to ...  \n",
       "4    What's it all about, Alfie?\\nIs it just for th...  \n",
       "..                                                 ...  \n",
       "415  We dance to the beat\\nWe dance to the beat\\nWe...  \n",
       "416  Thoughts about you and me \\nThinkin' about wha...  \n",
       "417  Good girls are pretty like all the time\\nI'm j...  \n",
       "418  Maybe we could make it all right\\nWe could mak...  \n",
       "419  Look at me here I am\\nI'm givin all of my lovi...  \n",
       "\n",
       "[420 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile lyrics by applying function to specified file path of lyric data\n",
    "lyrics_df = combine_lyrics_to_dataframe(lyrics_folder)\n",
    "lyrics_df  # Confirm both artists were added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "debcac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE ASSISTED BY CHATGPT4O\n",
    "# Creat function to read in Twitter data\n",
    "def combine_twitter_to_dataframe(directory):\n",
    "    data = []\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if \"_data\" in file and file.endswith(\".txt\"):  # Confirm files are text files that contain follower data\n",
    "                try:\n",
    "                    # Read the content of the file as tab-delimited, skipping bad lines\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    \n",
    "                    # Read in files as tab-delimited dataframe\n",
    "                    # Skip lines that have missing data or abnormal structure\n",
    "                    df_temp = pd.read_csv(file_path, delimiter='\\t', on_bad_lines = 'skip')\n",
    "\n",
    "                    # Extract the artist name from the file name since its the first keyword \n",
    "                    artist = file.split('_')[0]\n",
    "\n",
    "                    # Check if 'description' column exists in the df_temp\n",
    "                    if 'description' in df_temp.columns:\n",
    "                        # Append the artist name and the description column to the data list\n",
    "                        for description in df_temp['description']:\n",
    "                            data.append([artist, description])\n",
    "                    else:\n",
    "                        print(f\"Column 'description' not found in file {file}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "    # Create the final DataFrame\n",
    "    if data:\n",
    "        df = pd.DataFrame(data, columns=['artist', 'description'])\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['artist', 'description'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3534cedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cher</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cher</td>\n",
       "      <td>ùôøùöõùöòùöûùöç ùöúùöûùöôùöôùöòùöõùöùùöéùöõ ùöòùöè ùöñùöéùöúùöúùö¢ ùöãùöûùöóùöú &amp; ùöïùöéùöêùöêùöíùöóùöêùöú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cher</td>\n",
       "      <td>163„éùÔºèÊÑõ„Åã„Å£„Å∑üíú26Ê≠≥üçí Â∑•„ÄáÂ•Ω„Åç„Å™Â•≥„ÅÆÂ≠êüíì „Éï„Ç©„É≠„Éº„Åó„Å¶„Åè„Çå„Åü„ÇâDM„Åó„Åæ„Åôüß°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cher</td>\n",
       "      <td>csu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cher</td>\n",
       "      <td>Writer @Washinformer @SpelmanCollege alumna #D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268136</th>\n",
       "      <td>robynkonichiwa</td>\n",
       "      <td>singer of songs, type 1 diabetic, tired $jakel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268137</th>\n",
       "      <td>robynkonichiwa</td>\n",
       "      <td>Dadx2/ Con-Arch/ Photographer/ DK #stemgr√∏nnes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268138</th>\n",
       "      <td>robynkonichiwa</td>\n",
       "      <td>A year to change a life is still a year ‚ú®üòå</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268139</th>\n",
       "      <td>robynkonichiwa</td>\n",
       "      <td>Head of Consumer - Mango. Made in Melbourne. R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268140</th>\n",
       "      <td>robynkonichiwa</td>\n",
       "      <td>Stand for what is right, even if you stand alone.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4268141 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 artist                                        description\n",
       "0                  cher                                                NaN\n",
       "1                  cher           ùôøùöõùöòùöûùöç ùöúùöûùöôùöôùöòùöõùöùùöéùöõ ùöòùöè ùöñùöéùöúùöúùö¢ ùöãùöûùöóùöú & ùöïùöéùöêùöêùöíùöóùöêùöú\n",
       "2                  cher          163„éùÔºèÊÑõ„Åã„Å£„Å∑üíú26Ê≠≥üçí Â∑•„ÄáÂ•Ω„Åç„Å™Â•≥„ÅÆÂ≠êüíì „Éï„Ç©„É≠„Éº„Åó„Å¶„Åè„Çå„Åü„ÇâDM„Åó„Åæ„Åôüß°\n",
       "3                  cher                                                csu\n",
       "4                  cher  Writer @Washinformer @SpelmanCollege alumna #D...\n",
       "...                 ...                                                ...\n",
       "4268136  robynkonichiwa  singer of songs, type 1 diabetic, tired $jakel...\n",
       "4268137  robynkonichiwa  Dadx2/ Con-Arch/ Photographer/ DK #stemgr√∏nnes...\n",
       "4268138  robynkonichiwa         A year to change a life is still a year ‚ú®üòå\n",
       "4268139  robynkonichiwa  Head of Consumer - Mango. Made in Melbourne. R...\n",
       "4268140  robynkonichiwa  Stand for what is right, even if you stand alone.\n",
       "\n",
       "[4268141 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile twitter by applying function to specified file path of twitter data\n",
    "twitter_df = combine_twitter_to_dataframe(twitter_folder)\n",
    "twitter_df  # Confirm both artists were added along with descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f3b12",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b327033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE ASSISTED BY CHATGPT4O\n",
    "# Function to creat clean data\n",
    "def clean_and_tokenize(text):\n",
    "    # Explicitly remove apostrophes and quotes\n",
    "    additional_punctuation = \"‚Äô‚Äò‚Äú‚Äù\"  \n",
    "\n",
    "    # Replace additional punctuation with empty string\n",
    "    for char in additional_punctuation:\n",
    "        text = text.replace(char, \"\")\n",
    "        \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Split on whitespace and fold to lowercase\n",
    "    words = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in sw]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2f77dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Twitter data type to string\n",
    "twitter_df['description'] = twitter_df['description'].astype('str')\n",
    "\n",
    "# Update alternative NA descriptions to NA\n",
    "twitter_df['description'] = twitter_df['description'].replace(['nan', 'NaN'], pd.NA)\n",
    "\n",
    "# Fill in any missing values with empty strings\n",
    "twitter_df['description'] = twitter_df['description'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11f8b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text cleaning to twitter data\n",
    "twitter_df['clean_text'] = twitter_df['description'].apply(clean_and_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0f22e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update lyrics data type to string\n",
    "lyrics_df['lyrics'] = lyrics_df['lyrics'].astype('str')\n",
    "\n",
    "# Fill in any missing values with empty strings\n",
    "lyrics_df['lyrics'] = lyrics_df['lyrics'].fillna('')\n",
    "\n",
    "# Apply text cleaning to lyrics data\n",
    "lyrics_df['clean_text'] = lyrics_df['lyrics'].apply(clean_and_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf8086a",
   "metadata": {},
   "source": [
    "## Examine Clean Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebc79b3",
   "metadata": {},
   "source": [
    "### Twitter Before/After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40cda8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                     \n",
       "1             ùôøùöõùöòùöûùöç ùöúùöûùöôùöôùöòùöõùöùùöéùöõ ùöòùöè ùöñùöéùöúùöúùö¢ ùöãùöûùöóùöú & ùöïùöéùöêùöêùöíùöóùöêùöú\n",
       "2            163„éùÔºèÊÑõ„Åã„Å£„Å∑üíú26Ê≠≥üçí Â∑•„ÄáÂ•Ω„Åç„Å™Â•≥„ÅÆÂ≠êüíì „Éï„Ç©„É≠„Éº„Åó„Å¶„Åè„Çå„Åü„ÇâDM„Åó„Åæ„Åôüß°\n",
       "3                                                  csu\n",
       "4    Writer @Washinformer @SpelmanCollege alumna #D...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df['description'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba0ced83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   []\n",
       "1        [ùôøùöõùöòùöûùöç, ùöúùöûùöôùöôùöòùöõùöùùöéùöõ, ùöòùöè, ùöñùöéùöúùöúùö¢, ùöãùöûùöóùöú, ùöïùöéùöêùöêùöíùöóùöêùöú]\n",
       "2        [163„éùÔºèÊÑõ„Åã„Å£„Å∑üíú26Ê≠≥üçí, Â∑•„ÄáÂ•Ω„Åç„Å™Â•≥„ÅÆÂ≠êüíì, „Éï„Ç©„É≠„Éº„Åó„Å¶„Åè„Çå„Åü„Çâdm„Åó„Åæ„Åôüß°]\n",
       "3                                                [csu]\n",
       "4    [writer, washinformer, spelmancollege, alumna,...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da4e261",
   "metadata": {},
   "source": [
    "### Lyrics Before/After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d142a4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Stuck in L.A., ain't got no friends \\nAnd so H...\n",
       "1    What if the world was crazy and I was sane\\nWo...\n",
       "2    Well, here we are again\\nI guess it must be fa...\n",
       "3    Again evening finds me at your door \\nHere to ...\n",
       "4    What's it all about, Alfie?\\nIs it just for th...\n",
       "Name: lyrics, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df['lyrics'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa5bbfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [stuck, la, aint, got, friends, hollywood, nut...\n",
       "1    [world, crazy, sane, would, strange, cant, bel...\n",
       "2    [well, guess, must, fate, weve, tried, deep, i...\n",
       "3    [evening, finds, door, ask, could, try, dont, ...\n",
       "4    [whats, alfie, moment, live, whats, sort, alfi...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd0179",
   "metadata": {},
   "source": [
    "## Basic Descriptive Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29976ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE ASSISTED BY CHATGPT4O\n",
    "# Create function for desc stats for dataframe of tokens\n",
    "def descriptive_stats(token_lists, num_tokens=5, verbose=True):\n",
    "\n",
    "    # Flatten the list of lists\n",
    "    tokens = [token for sublist in token_lists for token in sublist]\n",
    "\n",
    "    # Calculate the required values\n",
    "    total_tokens = len(tokens)\n",
    "    unique_tokens = len(set(tokens))\n",
    "    num_characters = sum(len(token) for token in tokens)\n",
    "    lexical_diversity = unique_tokens / total_tokens if total_tokens > 0 else 0\n",
    "    \n",
    "    # Calculate the most common tokens\n",
    "    token_counts = Counter(tokens)\n",
    "    most_common_tokens = token_counts.most_common(num_tokens)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"There are {total_tokens} tokens in the data.\")\n",
    "        print(f\"There are {unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "        print(f\"The {num_tokens} most common tokens are:\")\n",
    "        for token, count in most_common_tokens:\n",
    "            print(f\"'{token}': {count} times\")\n",
    "    \n",
    "    return [total_tokens, unique_tokens, lexical_diversity, num_characters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0bbedd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 35684 tokens in the data.\n",
      "There are 3684 unique tokens in the data.\n",
      "There are 169160 characters in the data.\n",
      "The lexical diversity is 0.103 in the data.\n",
      "The 5 most common tokens are:\n",
      "'love': 966 times\n",
      "'im': 511 times\n",
      "'know': 480 times\n",
      "'dont': 430 times\n",
      "'na': 348 times\n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics for Cher - Lyrics\n",
    "cher_lyric_stats = descriptive_stats(lyrics_df['clean_text'][lyrics_df['artist'] == 'cher'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6e08634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15244 tokens in the data.\n",
      "There are 2138 unique tokens in the data.\n",
      "There are 72800 characters in the data.\n",
      "The lexical diversity is 0.140 in the data.\n",
      "The 5 most common tokens are:\n",
      "'know': 305 times\n",
      "'im': 299 times\n",
      "'dont': 297 times\n",
      "'got': 274 times\n",
      "'love': 269 times\n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistic for Robyn - Lyrics\n",
    "robyn_lyric_stats = descriptive_stats(lyrics_df['clean_text'][lyrics_df['artist'] == 'robyn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57423f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16141920 tokens in the data.\n",
      "There are 1679896 unique tokens in the data.\n",
      "There are 95853361 characters in the data.\n",
      "The lexical diversity is 0.104 in the data.\n",
      "The 5 most common tokens are:\n",
      "'love': 214772 times\n",
      "'im': 162148 times\n",
      "'life': 123262 times\n",
      "'music': 88222 times\n",
      "'de': 73286 times\n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics for Cher - Twitter\n",
    "cher_twitter_stats = descriptive_stats(twitter_df['clean_text'][twitter_df['artist'] == 'cher'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7445365f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1537870 tokens in the data.\n",
      "There are 268753 unique tokens in the data.\n",
      "There are 9384426 characters in the data.\n",
      "The lexical diversity is 0.175 in the data.\n",
      "The 5 most common tokens are:\n",
      "'music': 15172 times\n",
      "'love': 11705 times\n",
      "'im': 10224 times\n",
      "'och': 7923 times\n",
      "'life': 7413 times\n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics for Robyn - Twitter\n",
    "robyn_twitter_stats = descriptive_stats(twitter_df['clean_text'][twitter_df['artist'] == 'robynkonichiwa'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46294409",
   "metadata": {},
   "source": [
    "Q: How do you think the \"top 5 words\" would be different if we left stopwords in the data? \n",
    "\n",
    "A: If we left stopwords in the data, then the top 5 words would consist of stop words. \n",
    "\n",
    "---\n",
    "\n",
    "Q: What were your prior beliefs about the lexical diversity between the artists? Does the difference (or lack thereof) in lexical diversity between the artists conform to your prior beliefs? \n",
    "\n",
    "A: I expected that Cher would look different than Robyn due to her celebrity status, but the content appears to be very similar. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e1ac1",
   "metadata": {},
   "source": [
    "## Specialty Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "753a5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(emoji.is_emoji(\"‚ù§Ô∏è\"))\n",
    "assert(not emoji.is_emoji(\":-)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986fc4c0",
   "metadata": {},
   "source": [
    "### Emojis üòÅ\n",
    "\n",
    "What are the ten most common emojis by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "269cd433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract emojies\n",
    "def extract_emojis(text):\n",
    "    return [char for char in text if emoji.is_emoji(char)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f29769e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract emojis and hashtags from clean text of descriptions\n",
    "twitter_df['emojis'] = twitter_df['clean_text'].apply(extract_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d8b2455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten most common emojis by artist:\n",
      "{'cher': [('‚ù§Ô∏è', 14738), ('üè≥Ô∏è\\u200düåà', 14196), ('‚ô•', 10243), ('‚ù§', 9683), ('‚ú®', 8410), ('üåà', 5500), ('üá∫üá∏', 3738), ('üíô', 3709), ('üíú', 3511), ('üåä', 3303)], 'robynkonichiwa': [('üè≥Ô∏è\\u200düåà', 1710), ('‚ô•', 1170), ('‚ù§Ô∏è', 991), ('‚ú®', 756), ('‚ù§', 655), ('üåà', 572), ('üé∂', 273), ('üéß', 214), ('üñ§', 212), ('üíú', 207)]}\n"
     ]
    }
   ],
   "source": [
    "# CODE ASSISTED BY CHATGPT4O\n",
    "# Ten most common emojis by artist in the twitter descriptions\n",
    "def most_common_by_artist(df, column, top_n=10):\n",
    "    common_by_artist = {}\n",
    "    for artist, group in df.groupby('artist'):\n",
    "        all_items = [item for sublist in group[column] for item in sublist]\n",
    "        common_by_artist[artist] = Counter(all_items).most_common(top_n)\n",
    "    return common_by_artist\n",
    "\n",
    "common_emojis_by_artist = most_common_by_artist(twitter_df, 'emojis')\n",
    "print(\"Ten most common emojis by artist:\")\n",
    "print(common_emojis_by_artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab9b770",
   "metadata": {},
   "source": [
    "### Hashtags\n",
    "\n",
    "What are the ten most common hashtags by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07c396f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract hashtags\n",
    "def extract_hashtags(text):\n",
    "    return re.findall(r'#\\w+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d30d91fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update clean text to string data type\n",
    "twitter_df['description'] = twitter_df['description'].astype('str')\n",
    "twitter_df['hashtags'] = twitter_df['description'].apply(extract_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a94501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten most common hashtags by artist:\n",
      "{'cher': [('#BLM', 9532), ('#Resist', 6032), ('#BlackLivesMatter', 4675), ('#resist', 3793), ('#FBR', 3238), ('#TheResistance', 2992), ('#blacklivesmatter', 2645), ('#1', 2633), ('#Resistance', 1915), ('#RESIST', 1821)], 'robynkonichiwa': [('#BlackLivesMatter', 337), ('#BLM', 307), ('#blacklivesmatter', 208), ('#1', 199), ('#music', 174), ('#Music', 113), ('#EDM', 86), ('#LGBTQ', 75), ('#TeamFollowBack', 59), ('#blm', 56)]}\n"
     ]
    }
   ],
   "source": [
    "# CODE ASSISTED BY CHATGPT4O\n",
    "# Ten most common hashtags by artist in the twitter descriptions\n",
    "common_hashtags_by_artist = most_common_by_artist(twitter_df, 'hashtags')\n",
    "print(\"Ten most common hashtags by artist:\")\n",
    "print(common_hashtags_by_artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f21d5",
   "metadata": {},
   "source": [
    "### Song Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb69b36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five most common words in song titles by artist:\n",
      "{'cher': [('love', 38), ('man', 12), ('song', 11), ('dont', 10), ('come', 7)], 'robyn': [('love', 6), ('dont', 4), ('u', 4), ('thing', 3), ('girl', 3)]}\n"
     ]
    }
   ],
   "source": [
    "# CODE ASSISTED BY CHATGPT4O\n",
    "# Five most common words in song titles by artist\n",
    "def most_common_words_in_titles(df, column, top_n=5):\n",
    "    common_words_by_artist = {}\n",
    "    for artist, group in df.groupby('artist'):\n",
    "        all_titles = [word for sublist in group[column] for word in sublist]\n",
    "        common_words_by_artist[artist] = Counter(all_titles).most_common(top_n)\n",
    "    return common_words_by_artist\n",
    "\n",
    "# Song titles are in 'songname' column in compiled lyrics dataframe\n",
    "lyrics_df['cleaned_titles'] = lyrics_df['songname'].apply(clean_and_tokenize)\n",
    "common_words_in_titles_by_artist = most_common_words_in_titles(lyrics_df, 'cleaned_titles')\n",
    "print(\"Five most common words in song titles by artist:\")\n",
    "print(common_words_in_titles_by_artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd4fd71",
   "metadata": {},
   "source": [
    "### Song Lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde9ebb",
   "metadata": {},
   "source": [
    "Q: What does the regular expression `'\\s+'` match on? \n",
    "\n",
    "A: One or more spaces. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0e34516",
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_whitespace = re.compile(r'\\s+')\n",
    "\n",
    "def tokenize_lyrics(lyric) : \n",
    "    \"\"\"strip and split on whitespace\"\"\"\n",
    "    return([item.lower() for item in collapse_whitespace.split(lyric)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7df877d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update clean text to string data type\n",
    "lyrics_df['clean_text'] = lyrics_df['clean_text'].astype('str')\n",
    "\n",
    "# Apply to lyrics clean text\n",
    "lyrics_df['clean_space'] = lyrics_df['clean_text'].apply(tokenize_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "991037e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add song length variable\n",
    "lyrics_df['song_lengths'] = lyrics_df['clean_space'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1b3c39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    180\n",
       "1    133\n",
       "2    120\n",
       "3     34\n",
       "4     66\n",
       "Name: song_lengths, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df['song_lengths'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff931e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cher_length = lyrics_df['song_lengths'][lyrics_df['artist'] == 'cher']\n",
    "robyn_length = lyrics_df['song_lengths'][lyrics_df['artist'] == 'robyn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "814ffce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(316,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cher_length.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa567ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robyn_length.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d00646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(cher_length)\n",
    "# Add title and labels\n",
    "plt.title('Song Lengths for Cher')\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e93e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(robyn_length)\n",
    "# Add title and labels\n",
    "plt.title('Song Lengths for Robyn')\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
